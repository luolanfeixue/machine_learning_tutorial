{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import math\n",
    "import time\n",
    "import tensorflow as tf\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "num_batches = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def print_activations(t):\n",
    "    print(t.op.name,' ',t.get_shape().as_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def variable_with_weigth_loss(shape, name,stddev, w1):\n",
    "    var = tf.Variable(tf.truncated_normal(shape, stddev = stddev),name=name)\n",
    "    if w1 is not None:\n",
    "        weight_loss = tf.multiply(tf.nn.l2_loss(var), w1, name = 'weight_loss')\n",
    "        tf.add_to_collection('losses', weight_loss)\n",
    "    return var"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " * scope 内命名variable 则variabel会被自动命名为 scope_name/***, 便于区分不同层间的组件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def inference(images):\n",
    "    parameters = []\n",
    "    \n",
    "    with tf.name_scope('conv1') as scope:\n",
    "        kernel = tf.Variable(tf.truncated_normal([11, 11, 3, 64],dtype=tf.float32, stddev=1e-1), name='weights')\n",
    "        conv = tf.nn.conv2d(images, kernel, [1, 4, 4, 1], padding = 'SAME')\n",
    "        biases = tf.Variable(tf.constant(0.0, shape=[64], dtype=tf.float32), trainable=True, name='biases')\n",
    "        bias = tf.nn.bias_add(conv, biases)\n",
    "        conv1 = tf.nn.relu(bias, name=scope)\n",
    "        print_activations(conv1)\n",
    "        parameters += [kernel, biases]\n",
    "        \n",
    "    with tf.name_scope('lrn1') as scope:\n",
    "        lrn1 = tf.nn.lrn(conv1, depth_radius=4, bias=1.0, alpha=0.001/9, beta = 0.75, name = 'lrn1')\n",
    "    pool1 = tf.nn.max_pool(lrn1, ksize=[1, 3, 3, 1], strides=[1, 2, 2, 1], padding='VALID', name='pool1')\n",
    "    print_activations(pool1)\n",
    "    \n",
    "    with tf.name_scope('conv2') as scope:\n",
    "        kernel  = tf.Variable(tf.truncated_normal([5, 5, 64, 192], dtype=tf.float32, stddev=1e-1, name='weights'))\n",
    "        conv = tf.nn.conv2d(pool1, kernel, [1, 1, 1, 1], padding='SAME')\n",
    "        biases = tf.Variable(tf.constant(0.0, shape=[192], dtype=tf.float32), trainable=True, name='biases')\n",
    "        bias = tf.nn.bias_add(conv, biases)\n",
    "        conv2 = tf.nn.relu(bias, name=scope) \n",
    "        parameters += [kernel, biases]\n",
    "    print_activations(conv2)\n",
    "    \n",
    "    with tf.name_scope('lrn2') as scope:\n",
    "        lrn2= tf.nn.lrn(conv2, depth_radius=4, bias=1.0, alpha=0.001/9, beta=0.75, name='lrn2')\n",
    "    pool2 = tf.nn.max_pool(lrn2, ksize=[1, 3, 3, 1], strides=[1, 2, 2, 1], padding='VALID', name='pool2')\n",
    "    print_activations(pool2)\n",
    "    \n",
    "    \n",
    "    with tf.name_scope('conv3') as scope:\n",
    "        kernel = tf.Variable(tf.truncated_normal([3, 3, 192, 384], dtype=tf.float32, stddev=1e-1, name='weights'))\n",
    "        conv = tf.nn.conv2d(pool2, kernel, [1, 1, 1, 1], padding='SAME')\n",
    "        biases = tf.Variable(tf.constant(0.0, shape=[384], dtype=tf.float32), trainable=True, name='biases')\n",
    "        bias = tf.nn.bias_add(conv, biases)\n",
    "        conv3 = tf.nn.relu(bias, name=scope)\n",
    "        parameters += [kernel, biases]\n",
    "    print_activations(conv3)\n",
    "    \n",
    "    with tf.name_scope('conv4') as scope:\n",
    "        kernel = tf.Variable(tf.truncated_normal([3, 3, 384, 256], dtype=tf.float32, stddev=1e-1, name='weights'))\n",
    "        conv = tf.nn.conv2d(conv3, kernel, [1, 1, 1, 1], padding='SAME')\n",
    "        biases = tf.Variable(tf.constant(0.0, shape=[256], dtype=tf.float32), trainable=True, name='biases')\n",
    "        bias = tf.nn.bias_add(conv, biases)\n",
    "        conv4 = tf.nn.relu(bias, name=scope)\n",
    "        parameters += [kernel, biases]\n",
    "    print_activations(conv4)  \n",
    "    \n",
    "    with tf.name_scope('conv5') as scope:\n",
    "        kernel = tf.Variable(tf.truncated_normal([3, 3, 256, 256], dtype=tf.float32, stddev=1e-1, name='weights'))\n",
    "        conv = tf.nn.conv2d(conv4, kernel, [1, 1, 1, 1], padding='SAME')\n",
    "        biases = tf.Variable(tf.constant(0.0, shape=[256], dtype=tf.float32), trainable=True, name='biases')\n",
    "        bias = tf.nn.bias_add(conv, biases)\n",
    "        conv5 = tf.nn.relu(bias, name=scope)\n",
    "        parameters += [kernel, biases]\n",
    "    print_activations(conv5)  \n",
    "    pool5  = tf.nn.max_pool(conv5, ksize=[1, 3, 3, 1], strides=[1, 2, 2, 1], padding='VALID', name='pool5')\n",
    "    print_activations(pool5)\n",
    "    \n",
    "    with tf.name_scope('fully1') as scope:\n",
    "        reshape = tf.reshape(conv5, [batch_size, -1])\n",
    "        dim = reshape.get_shape()[1].value\n",
    "        weight = variable_with_weigth_loss(shape=[dim,4096], name='weights',stddev=0.04, w1=0.004)\n",
    "        bias = tf.Variable(tf.constant(0.1, shape=[4096]))\n",
    "        fully1 = tf.nn.relu(tf.matmul(reshape, weight) + bias)\n",
    "        parameters += [weight, bias]\n",
    "    \n",
    "    print_activations(fully1)\n",
    "    with tf.name_scope('fully2') as scope:\n",
    "        weight = variable_with_weigth_loss(shape=[4096,4096], name='weights',stddev=0.04, w1=0.004)\n",
    "        bias = tf.Variable(tf.constant(0.1, shape=[4096]))\n",
    "        fully2 = tf.nn.relu(tf.matmul(fully1, weight) + bias)\n",
    "        parameters += [weight, bias]\n",
    "    print_activations(fully2)  \n",
    "    \n",
    "    \n",
    "    with tf.name_scope('fully3') as scope:\n",
    "        weight = variable_with_weigth_loss(shape=[4096,1000], name='weights',stddev=0.04, w1=0.004)\n",
    "        bias = tf.Variable(tf.constant(0.1, shape=[1000]))\n",
    "        fully3 = tf.nn.relu(tf.matmul(fully2, weight) + bias)\n",
    "        parameters += [weight, bias]\n",
    "    print_activations(fully3)  \n",
    "\n",
    "    return fully3, parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def time_tensorflow_run(session, target, info_string):\n",
    "    num_steps_burn_in = 10\n",
    "    total_duration = 0.0\n",
    "    total_duration_squared = 0.0\n",
    "    for i in range(num_batches + num_steps_burn_in):\n",
    "        start_time =time.time()\n",
    "        _ = session.run(target)\n",
    "        duration = time.time() - start_time;\n",
    "        if i >= num_steps_burn_in:\n",
    "            if not i % 10 :\n",
    "                print('%s: step%d, duration = %.3f' % (datetime.now(), i - num_steps_burn_in, duration))\n",
    "            total_duration += duration;\n",
    "            total_duration_squared += duration*duration\n",
    "        mn = total_duration / num_batches\n",
    "        vr = total_duration_squared / num_batches - mn* mn\n",
    "        sd = math.sqrt(vr)\n",
    "        print('$%s : %s across %d steps, %.3f +/- %.3f sec /batch' % (datetime.now(), info_string, num_batches, mn, sd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def loss(logits,labels):\n",
    "    labels = tf.cast(labels, tf.float32)\n",
    "    cross_entropy = tf.nn.sparse_softmax_cross_entropy_with_logits(logits = logits, \n",
    "                                                                   labels = labels, \n",
    "                                                                   name = 'cross_entropy_per_example')\n",
    "    cross_entropy_mean = tf.reduce_mean(cross_entropy, name = 'cross_entropy')\n",
    "    tf.add_to_collection('losses', cross_entropy_mean)\n",
    "    return tf.add_n(tf.get_collection('losses'), name = 'total_loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run_benchmark():\n",
    "    with tf.Graph().as_default():\n",
    "        image_size = 224\n",
    "        images = tf.Variable(tf.random_normal([batch_size, image_size, image_size, 3], dtype=tf.float32, stddev=1e-1))\n",
    "        fully3, parameters = inference(images)\n",
    "        init = tf.global_variables_initializer()\n",
    "        sess = tf.Session()\n",
    "        sess.run(init)\n",
    "        \n",
    "        time_tensorflow_run(sess, fully3, \"Forward\")\n",
    "        \n",
    "        objective = tf.nn.l2_loss(fully3)\n",
    "        grad = tf.gradients(objective, parameters)\n",
    "        time_tensorflow_run(sess, grad, \"Forward-backward\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1   [32, 56, 56, 64]\n",
      "pool1   [32, 27, 27, 64]\n",
      "conv2   [32, 27, 27, 192]\n",
      "pool2   [32, 13, 13, 192]\n",
      "conv3   [32, 13, 13, 384]\n",
      "conv4   [32, 13, 13, 256]\n",
      "conv5   [32, 13, 13, 256]\n",
      "pool5   [32, 6, 6, 256]\n",
      "fully1/Relu   [32, 4096]\n",
      "fully2/Relu   [32, 4096]\n",
      "fully3/Relu   [32, 1000]\n",
      "$2018-11-10 19:37:34.785199 : Forward across 100 steps, 0.000 +/- 0.000 sec /batch\n",
      "$2018-11-10 19:37:34.804978 : Forward across 100 steps, 0.000 +/- 0.000 sec /batch\n",
      "$2018-11-10 19:37:34.824511 : Forward across 100 steps, 0.000 +/- 0.000 sec /batch\n",
      "$2018-11-10 19:37:34.843982 : Forward across 100 steps, 0.000 +/- 0.000 sec /batch\n",
      "$2018-11-10 19:37:34.863581 : Forward across 100 steps, 0.000 +/- 0.000 sec /batch\n",
      "$2018-11-10 19:37:34.883197 : Forward across 100 steps, 0.000 +/- 0.000 sec /batch\n",
      "$2018-11-10 19:37:34.902981 : Forward across 100 steps, 0.000 +/- 0.000 sec /batch\n",
      "$2018-11-10 19:37:34.922325 : Forward across 100 steps, 0.000 +/- 0.000 sec /batch\n",
      "$2018-11-10 19:37:34.942151 : Forward across 100 steps, 0.000 +/- 0.000 sec /batch\n",
      "$2018-11-10 19:37:34.961696 : Forward across 100 steps, 0.000 +/- 0.000 sec /batch\n",
      "2018-11-10 19:37:34.981324: step0, duration = 0.020\n",
      "$2018-11-10 19:37:34.981411 : Forward across 100 steps, 0.000 +/- 0.002 sec /batch\n",
      "$2018-11-10 19:37:35.000771 : Forward across 100 steps, 0.000 +/- 0.003 sec /batch\n",
      "$2018-11-10 19:37:35.020007 : Forward across 100 steps, 0.001 +/- 0.003 sec /batch\n",
      "$2018-11-10 19:37:35.039353 : Forward across 100 steps, 0.001 +/- 0.004 sec /batch\n",
      "$2018-11-10 19:37:35.058633 : Forward across 100 steps, 0.001 +/- 0.004 sec /batch\n",
      "$2018-11-10 19:37:35.077890 : Forward across 100 steps, 0.001 +/- 0.005 sec /batch\n",
      "$2018-11-10 19:37:35.097078 : Forward across 100 steps, 0.001 +/- 0.005 sec /batch\n",
      "$2018-11-10 19:37:35.116450 : Forward across 100 steps, 0.002 +/- 0.005 sec /batch\n",
      "$2018-11-10 19:37:35.135924 : Forward across 100 steps, 0.002 +/- 0.006 sec /batch\n",
      "$2018-11-10 19:37:35.155253 : Forward across 100 steps, 0.002 +/- 0.006 sec /batch\n",
      "2018-11-10 19:37:35.174502: step10, duration = 0.019\n",
      "$2018-11-10 19:37:35.174602 : Forward across 100 steps, 0.002 +/- 0.006 sec /batch\n",
      "$2018-11-10 19:37:35.193773 : Forward across 100 steps, 0.002 +/- 0.006 sec /batch\n",
      "$2018-11-10 19:37:35.212967 : Forward across 100 steps, 0.002 +/- 0.006 sec /batch\n",
      "$2018-11-10 19:37:35.232204 : Forward across 100 steps, 0.003 +/- 0.007 sec /batch\n",
      "$2018-11-10 19:37:35.251446 : Forward across 100 steps, 0.003 +/- 0.007 sec /batch\n",
      "$2018-11-10 19:37:35.270649 : Forward across 100 steps, 0.003 +/- 0.007 sec /batch\n",
      "$2018-11-10 19:37:35.290008 : Forward across 100 steps, 0.003 +/- 0.007 sec /batch\n",
      "$2018-11-10 19:37:35.309097 : Forward across 100 steps, 0.003 +/- 0.007 sec /batch\n",
      "$2018-11-10 19:37:35.328553 : Forward across 100 steps, 0.004 +/- 0.008 sec /batch\n",
      "$2018-11-10 19:37:35.347820 : Forward across 100 steps, 0.004 +/- 0.008 sec /batch\n",
      "2018-11-10 19:37:35.366836: step20, duration = 0.019\n",
      "$2018-11-10 19:37:35.366921 : Forward across 100 steps, 0.004 +/- 0.008 sec /batch\n",
      "$2018-11-10 19:37:35.386046 : Forward across 100 steps, 0.004 +/- 0.008 sec /batch\n",
      "$2018-11-10 19:37:35.405016 : Forward across 100 steps, 0.004 +/- 0.008 sec /batch\n",
      "$2018-11-10 19:37:35.425037 : Forward across 100 steps, 0.005 +/- 0.008 sec /batch\n",
      "$2018-11-10 19:37:35.444418 : Forward across 100 steps, 0.005 +/- 0.008 sec /batch\n",
      "$2018-11-10 19:37:35.463553 : Forward across 100 steps, 0.005 +/- 0.008 sec /batch\n",
      "$2018-11-10 19:37:35.482790 : Forward across 100 steps, 0.005 +/- 0.009 sec /batch\n",
      "$2018-11-10 19:37:35.501958 : Forward across 100 steps, 0.005 +/- 0.009 sec /batch\n",
      "$2018-11-10 19:37:35.521124 : Forward across 100 steps, 0.006 +/- 0.009 sec /batch\n",
      "$2018-11-10 19:37:35.540355 : Forward across 100 steps, 0.006 +/- 0.009 sec /batch\n",
      "2018-11-10 19:37:35.559588: step30, duration = 0.019\n",
      "$2018-11-10 19:37:35.559731 : Forward across 100 steps, 0.006 +/- 0.009 sec /batch\n",
      "$2018-11-10 19:37:35.578915 : Forward across 100 steps, 0.006 +/- 0.009 sec /batch\n",
      "$2018-11-10 19:37:35.598080 : Forward across 100 steps, 0.006 +/- 0.009 sec /batch\n",
      "$2018-11-10 19:37:35.617480 : Forward across 100 steps, 0.007 +/- 0.009 sec /batch\n",
      "$2018-11-10 19:37:35.636695 : Forward across 100 steps, 0.007 +/- 0.009 sec /batch\n",
      "$2018-11-10 19:37:35.655793 : Forward across 100 steps, 0.007 +/- 0.009 sec /batch\n",
      "$2018-11-10 19:37:35.675046 : Forward across 100 steps, 0.007 +/- 0.009 sec /batch\n",
      "$2018-11-10 19:37:35.694006 : Forward across 100 steps, 0.007 +/- 0.009 sec /batch\n",
      "$2018-11-10 19:37:35.712873 : Forward across 100 steps, 0.007 +/- 0.009 sec /batch\n",
      "$2018-11-10 19:37:35.731939 : Forward across 100 steps, 0.008 +/- 0.009 sec /batch\n",
      "2018-11-10 19:37:35.750747: step40, duration = 0.019\n",
      "$2018-11-10 19:37:35.750790 : Forward across 100 steps, 0.008 +/- 0.009 sec /batch\n",
      "$2018-11-10 19:37:35.769682 : Forward across 100 steps, 0.008 +/- 0.009 sec /batch\n",
      "$2018-11-10 19:37:35.788569 : Forward across 100 steps, 0.008 +/- 0.009 sec /batch\n",
      "$2018-11-10 19:37:35.807460 : Forward across 100 steps, 0.008 +/- 0.009 sec /batch\n",
      "$2018-11-10 19:37:35.826960 : Forward across 100 steps, 0.009 +/- 0.010 sec /batch\n",
      "$2018-11-10 19:37:35.846122 : Forward across 100 steps, 0.009 +/- 0.010 sec /batch\n",
      "$2018-11-10 19:37:35.865157 : Forward across 100 steps, 0.009 +/- 0.010 sec /batch\n",
      "$2018-11-10 19:37:35.884083 : Forward across 100 steps, 0.009 +/- 0.010 sec /batch\n",
      "$2018-11-10 19:37:35.903098 : Forward across 100 steps, 0.009 +/- 0.010 sec /batch\n",
      "$2018-11-10 19:37:35.921986 : Forward across 100 steps, 0.010 +/- 0.010 sec /batch\n",
      "2018-11-10 19:37:35.941119: step50, duration = 0.019\n",
      "$2018-11-10 19:37:35.941156 : Forward across 100 steps, 0.010 +/- 0.010 sec /batch\n",
      "$2018-11-10 19:37:35.959915 : Forward across 100 steps, 0.010 +/- 0.010 sec /batch\n",
      "$2018-11-10 19:37:35.978655 : Forward across 100 steps, 0.010 +/- 0.010 sec /batch\n",
      "$2018-11-10 19:37:35.997412 : Forward across 100 steps, 0.010 +/- 0.010 sec /batch\n",
      "$2018-11-10 19:37:36.016184 : Forward across 100 steps, 0.010 +/- 0.009 sec /batch\n",
      "$2018-11-10 19:37:36.035151 : Forward across 100 steps, 0.011 +/- 0.009 sec /batch\n",
      "$2018-11-10 19:37:36.054092 : Forward across 100 steps, 0.011 +/- 0.009 sec /batch\n",
      "$2018-11-10 19:37:36.073175 : Forward across 100 steps, 0.011 +/- 0.009 sec /batch\n",
      "$2018-11-10 19:37:36.092099 : Forward across 100 steps, 0.011 +/- 0.009 sec /batch\n",
      "$2018-11-10 19:37:36.111026 : Forward across 100 steps, 0.011 +/- 0.009 sec /batch\n",
      "2018-11-10 19:37:36.129911: step60, duration = 0.019\n",
      "$2018-11-10 19:37:36.129971 : Forward across 100 steps, 0.012 +/- 0.009 sec /batch\n",
      "$2018-11-10 19:37:36.149015 : Forward across 100 steps, 0.012 +/- 0.009 sec /batch\n",
      "$2018-11-10 19:37:36.168007 : Forward across 100 steps, 0.012 +/- 0.009 sec /batch\n",
      "$2018-11-10 19:37:36.186893 : Forward across 100 steps, 0.012 +/- 0.009 sec /batch\n",
      "$2018-11-10 19:37:36.206262 : Forward across 100 steps, 0.012 +/- 0.009 sec /batch\n",
      "$2018-11-10 19:37:36.225430 : Forward across 100 steps, 0.013 +/- 0.009 sec /batch\n",
      "$2018-11-10 19:37:36.244596 : Forward across 100 steps, 0.013 +/- 0.009 sec /batch\n",
      "$2018-11-10 19:37:36.263668 : Forward across 100 steps, 0.013 +/- 0.009 sec /batch\n",
      "$2018-11-10 19:37:36.282406 : Forward across 100 steps, 0.013 +/- 0.009 sec /batch\n",
      "$2018-11-10 19:37:36.301300 : Forward across 100 steps, 0.013 +/- 0.009 sec /batch\n",
      "2018-11-10 19:37:36.320071: step70, duration = 0.019\n",
      "$2018-11-10 19:37:36.320113 : Forward across 100 steps, 0.014 +/- 0.009 sec /batch\n",
      "$2018-11-10 19:37:36.339011 : Forward across 100 steps, 0.014 +/- 0.009 sec /batch\n",
      "$2018-11-10 19:37:36.357981 : Forward across 100 steps, 0.014 +/- 0.008 sec /batch\n",
      "$2018-11-10 19:37:36.377030 : Forward across 100 steps, 0.014 +/- 0.008 sec /batch\n",
      "$2018-11-10 19:37:36.396023 : Forward across 100 steps, 0.014 +/- 0.008 sec /batch\n",
      "$2018-11-10 19:37:36.414869 : Forward across 100 steps, 0.014 +/- 0.008 sec /batch\n",
      "$2018-11-10 19:37:36.433849 : Forward across 100 steps, 0.015 +/- 0.008 sec /batch\n",
      "$2018-11-10 19:37:36.452779 : Forward across 100 steps, 0.015 +/- 0.008 sec /batch\n",
      "$2018-11-10 19:37:36.471810 : Forward across 100 steps, 0.015 +/- 0.008 sec /batch\n",
      "$2018-11-10 19:37:36.490801 : Forward across 100 steps, 0.015 +/- 0.008 sec /batch\n",
      "2018-11-10 19:37:36.509785: step80, duration = 0.019\n",
      "$2018-11-10 19:37:36.509834 : Forward across 100 steps, 0.015 +/- 0.007 sec /batch\n",
      "$2018-11-10 19:37:36.528921 : Forward across 100 steps, 0.016 +/- 0.007 sec /batch\n",
      "$2018-11-10 19:37:36.547921 : Forward across 100 steps, 0.016 +/- 0.007 sec /batch\n",
      "$2018-11-10 19:37:36.566992 : Forward across 100 steps, 0.016 +/- 0.007 sec /batch\n",
      "$2018-11-10 19:37:36.585862 : Forward across 100 steps, 0.016 +/- 0.007 sec /batch\n",
      "$2018-11-10 19:37:36.604685 : Forward across 100 steps, 0.016 +/- 0.007 sec /batch\n",
      "$2018-11-10 19:37:36.624358 : Forward across 100 steps, 0.017 +/- 0.006 sec /batch\n",
      "$2018-11-10 19:37:36.643543 : Forward across 100 steps, 0.017 +/- 0.006 sec /batch\n",
      "$2018-11-10 19:37:36.662548 : Forward across 100 steps, 0.017 +/- 0.006 sec /batch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "$2018-11-10 19:37:36.681373 : Forward across 100 steps, 0.017 +/- 0.006 sec /batch\n",
      "2018-11-10 19:37:36.700241: step90, duration = 0.019\n",
      "$2018-11-10 19:37:36.700290 : Forward across 100 steps, 0.017 +/- 0.005 sec /batch\n",
      "$2018-11-10 19:37:36.719287 : Forward across 100 steps, 0.017 +/- 0.005 sec /batch\n",
      "$2018-11-10 19:37:36.738329 : Forward across 100 steps, 0.018 +/- 0.005 sec /batch\n",
      "$2018-11-10 19:37:36.757294 : Forward across 100 steps, 0.018 +/- 0.005 sec /batch\n",
      "$2018-11-10 19:37:36.776150 : Forward across 100 steps, 0.018 +/- 0.004 sec /batch\n",
      "$2018-11-10 19:37:36.795281 : Forward across 100 steps, 0.018 +/- 0.004 sec /batch\n",
      "$2018-11-10 19:37:36.814098 : Forward across 100 steps, 0.018 +/- 0.003 sec /batch\n",
      "$2018-11-10 19:37:36.832926 : Forward across 100 steps, 0.019 +/- 0.003 sec /batch\n",
      "$2018-11-10 19:37:36.851755 : Forward across 100 steps, 0.019 +/- 0.002 sec /batch\n",
      "$2018-11-10 19:37:36.870873 : Forward across 100 steps, 0.019 +/- 0.000 sec /batch\n",
      "$2018-11-10 19:37:37.393874 : Forward-backward across 100 steps, 0.000 +/- 0.000 sec /batch\n",
      "$2018-11-10 19:37:37.737764 : Forward-backward across 100 steps, 0.000 +/- 0.000 sec /batch\n",
      "$2018-11-10 19:37:37.820967 : Forward-backward across 100 steps, 0.000 +/- 0.000 sec /batch\n",
      "$2018-11-10 19:37:37.904678 : Forward-backward across 100 steps, 0.000 +/- 0.000 sec /batch\n",
      "$2018-11-10 19:37:37.987370 : Forward-backward across 100 steps, 0.000 +/- 0.000 sec /batch\n",
      "$2018-11-10 19:37:38.069533 : Forward-backward across 100 steps, 0.000 +/- 0.000 sec /batch\n",
      "$2018-11-10 19:37:38.151383 : Forward-backward across 100 steps, 0.000 +/- 0.000 sec /batch\n",
      "$2018-11-10 19:37:38.233413 : Forward-backward across 100 steps, 0.000 +/- 0.000 sec /batch\n",
      "$2018-11-10 19:37:38.316127 : Forward-backward across 100 steps, 0.000 +/- 0.000 sec /batch\n",
      "$2018-11-10 19:37:38.398910 : Forward-backward across 100 steps, 0.000 +/- 0.000 sec /batch\n",
      "2018-11-10 19:37:38.481507: step0, duration = 0.083\n",
      "$2018-11-10 19:37:38.481550 : Forward-backward across 100 steps, 0.001 +/- 0.008 sec /batch\n",
      "$2018-11-10 19:37:38.563594 : Forward-backward across 100 steps, 0.002 +/- 0.012 sec /batch\n",
      "$2018-11-10 19:37:38.645717 : Forward-backward across 100 steps, 0.002 +/- 0.014 sec /batch\n",
      "$2018-11-10 19:37:38.727881 : Forward-backward across 100 steps, 0.003 +/- 0.016 sec /batch\n",
      "$2018-11-10 19:37:38.810381 : Forward-backward across 100 steps, 0.004 +/- 0.018 sec /batch\n",
      "$2018-11-10 19:37:38.892790 : Forward-backward across 100 steps, 0.005 +/- 0.020 sec /batch\n",
      "$2018-11-10 19:37:38.975470 : Forward-backward across 100 steps, 0.006 +/- 0.021 sec /batch\n",
      "$2018-11-10 19:37:39.058551 : Forward-backward across 100 steps, 0.007 +/- 0.022 sec /batch\n",
      "$2018-11-10 19:37:39.141391 : Forward-backward across 100 steps, 0.007 +/- 0.024 sec /batch\n",
      "$2018-11-10 19:37:39.224326 : Forward-backward across 100 steps, 0.008 +/- 0.025 sec /batch\n",
      "2018-11-10 19:37:39.306600: step10, duration = 0.082\n",
      "$2018-11-10 19:37:39.306638 : Forward-backward across 100 steps, 0.009 +/- 0.026 sec /batch\n",
      "$2018-11-10 19:37:39.388867 : Forward-backward across 100 steps, 0.010 +/- 0.027 sec /batch\n",
      "$2018-11-10 19:37:39.471311 : Forward-backward across 100 steps, 0.011 +/- 0.028 sec /batch\n",
      "$2018-11-10 19:37:39.553613 : Forward-backward across 100 steps, 0.012 +/- 0.029 sec /batch\n",
      "$2018-11-10 19:37:39.635896 : Forward-backward across 100 steps, 0.012 +/- 0.029 sec /batch\n",
      "$2018-11-10 19:37:39.718121 : Forward-backward across 100 steps, 0.013 +/- 0.030 sec /batch\n",
      "$2018-11-10 19:37:39.800606 : Forward-backward across 100 steps, 0.014 +/- 0.031 sec /batch\n",
      "$2018-11-10 19:37:39.883160 : Forward-backward across 100 steps, 0.015 +/- 0.032 sec /batch\n",
      "$2018-11-10 19:37:39.965683 : Forward-backward across 100 steps, 0.016 +/- 0.032 sec /batch\n",
      "$2018-11-10 19:37:40.048429 : Forward-backward across 100 steps, 0.016 +/- 0.033 sec /batch\n",
      "2018-11-10 19:37:40.131491: step20, duration = 0.083\n",
      "$2018-11-10 19:37:40.131562 : Forward-backward across 100 steps, 0.017 +/- 0.034 sec /batch\n",
      "$2018-11-10 19:37:40.214485 : Forward-backward across 100 steps, 0.018 +/- 0.034 sec /batch\n",
      "$2018-11-10 19:37:40.297781 : Forward-backward across 100 steps, 0.019 +/- 0.035 sec /batch\n",
      "$2018-11-10 19:37:40.380713 : Forward-backward across 100 steps, 0.020 +/- 0.035 sec /batch\n",
      "$2018-11-10 19:37:40.463728 : Forward-backward across 100 steps, 0.021 +/- 0.036 sec /batch\n",
      "$2018-11-10 19:37:40.546631 : Forward-backward across 100 steps, 0.021 +/- 0.036 sec /batch\n",
      "$2018-11-10 19:37:40.629649 : Forward-backward across 100 steps, 0.022 +/- 0.037 sec /batch\n",
      "$2018-11-10 19:37:40.712784 : Forward-backward across 100 steps, 0.023 +/- 0.037 sec /batch\n",
      "$2018-11-10 19:37:40.795893 : Forward-backward across 100 steps, 0.024 +/- 0.037 sec /batch\n",
      "$2018-11-10 19:37:40.878676 : Forward-backward across 100 steps, 0.025 +/- 0.038 sec /batch\n",
      "2018-11-10 19:37:40.961309: step30, duration = 0.082\n",
      "$2018-11-10 19:37:40.961371 : Forward-backward across 100 steps, 0.026 +/- 0.038 sec /batch\n",
      "$2018-11-10 19:37:41.043978 : Forward-backward across 100 steps, 0.026 +/- 0.039 sec /batch\n",
      "$2018-11-10 19:37:41.126253 : Forward-backward across 100 steps, 0.027 +/- 0.039 sec /batch\n",
      "$2018-11-10 19:37:41.208305 : Forward-backward across 100 steps, 0.028 +/- 0.039 sec /batch\n",
      "$2018-11-10 19:37:41.290417 : Forward-backward across 100 steps, 0.029 +/- 0.039 sec /batch\n",
      "$2018-11-10 19:37:41.372694 : Forward-backward across 100 steps, 0.030 +/- 0.040 sec /batch\n",
      "$2018-11-10 19:37:41.455243 : Forward-backward across 100 steps, 0.031 +/- 0.040 sec /batch\n",
      "$2018-11-10 19:37:41.538170 : Forward-backward across 100 steps, 0.031 +/- 0.040 sec /batch\n",
      "$2018-11-10 19:37:41.620868 : Forward-backward across 100 steps, 0.032 +/- 0.040 sec /batch\n",
      "$2018-11-10 19:37:41.703216 : Forward-backward across 100 steps, 0.033 +/- 0.040 sec /batch\n",
      "2018-11-10 19:37:41.785542: step40, duration = 0.082\n",
      "$2018-11-10 19:37:41.785615 : Forward-backward across 100 steps, 0.034 +/- 0.041 sec /batch\n",
      "$2018-11-10 19:37:41.868541 : Forward-backward across 100 steps, 0.035 +/- 0.041 sec /batch\n"
     ]
    }
   ],
   "source": [
    "run_benchmark()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
